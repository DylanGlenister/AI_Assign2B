{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c14d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from datetime import date, datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f7885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "raw_data = pd.read_csv(\n",
    "\t'./scats_data.csv',\n",
    "\tdtype={\n",
    "\t\t'SCATS Number': int,\n",
    "\t\t'Location': str,\n",
    "\t\t'NB_LATITUDE': float,\n",
    "\t\t'NB_LONGITUDE': float\n",
    "\t}\n",
    ")\n",
    "\n",
    "# Rename select columns\n",
    "raw_data.rename(columns={\n",
    "\t'SCATS Number': 'SCATS',\n",
    "\t'NB_LATITUDE': 'Latitude',\n",
    "\t'NB_LONGITUDE': 'Longitude',\n",
    "}, inplace=True)\n",
    "\n",
    "# SCATS is the intersection ID\n",
    "# Location is [owner road] [direction from intersection] [other road in intersection]\n",
    "\n",
    "raw_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Fix Auburn N/Burwood intersection missing position\n",
    "# https://www.openstreetmap.org/way/1092802786#map=19/-37.823687/145.045020\n",
    "# south: -37.82542, 145.04346\n",
    "# east: -37.82529, 145.04387\n",
    "# west: -37.82518, 145.04301\n",
    "# north: -37.82505, 145.04346 (estimated by Claude)\n",
    "def fix_burwood_auburn_latitude(_latitude: float):\n",
    "\t# Do it this funky way to avoid floating point nonsense\n",
    "\tif _latitude == 0:\n",
    "\t\treturn -37.82505\n",
    "\telse:\n",
    "\t\treturn _latitude\n",
    "\n",
    "def fix_burwood_auburn_longitude(_longitude: float):\n",
    "\tif _longitude == 0:\n",
    "\t\treturn 145.04346\n",
    "\telse:\n",
    "\t\treturn _longitude\n",
    "\n",
    "raw_data['Latitude'] = raw_data['Latitude'].apply(fix_burwood_auburn_latitude)\n",
    "raw_data['Longitude'] = raw_data['Longitude'].apply(fix_burwood_auburn_longitude)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa25153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import site reference\n",
    "raw_reference = pd.read_csv(\n",
    "\t'./scats_reference.csv',\n",
    "\tnames=['SCATS', 'Intersection', 'Site_Type'],\n",
    "\theader=0,\n",
    "\tdtype={\n",
    "\t\t'SCATS': np.int32,\n",
    "\t\t'Intersection': str,\n",
    "\t\t'Site_Type': str\n",
    "\t}\n",
    ")\n",
    "\n",
    "raw_reference.drop_duplicates(inplace=True)\n",
    "# Remove any site that isn't an intersection (rest are unused)\n",
    "raw_reference = raw_reference[raw_reference.Site_Type == 'INT']\n",
    "raw_reference.drop(columns={'Site_Type'}, inplace=True)\n",
    "raw_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085acc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an inner merge to keep only SCATS sites present in both tables\n",
    "merged_df = pd.merge(raw_reference, raw_data, on='SCATS', how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a247968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract location information\n",
    "extracted = merged_df.copy()\n",
    "\n",
    "def process_location(_locations: pd.Series):\n",
    "\tstreets: list[str] = []\n",
    "\tdirections: list[str] = []\n",
    "\n",
    "\tfor _, item in _locations.items():\n",
    "\t\tparts: list[str] = re.split(' of ', item, flags=re.IGNORECASE)\n",
    "\t\tfirst_part = parts[0]\n",
    "\n",
    "\t\t# Get all words in the first part\n",
    "\t\twords = first_part.split()\n",
    "\n",
    "\t\t# Last word is the direction, everything before is the street\n",
    "\t\tdirection = words[-1]\n",
    "\t\tstreet = ' '.join(words[:-1])\n",
    "\n",
    "\t\tstreets.append(street)\n",
    "\t\tdirections.append(direction)\n",
    "\n",
    "\treturn streets, directions\n",
    "\n",
    "streets, direction = process_location(extracted['Location'])\n",
    "extracted.insert(3, 'Street', pd.Series(streets))\n",
    "extracted.insert(4, 'Direction', pd.Series(direction))\n",
    "\n",
    "def process_date(_dates: pd.Series):\n",
    "\t#dates: list[str] = []\n",
    "\t#years: list[int] = []\n",
    "\t#months:list[int] = []\n",
    "\t#days: list[int] = []\n",
    "\t#day_indexes: list[int] = []\n",
    "\tdays_of_week = []\n",
    "\n",
    "\tfor _, item in _dates.items():\n",
    "\t\t# Import as a datetime object\n",
    "\t\tdate_obj = datetime.strptime(item, '%d/%m/%Y')\n",
    "\t\t#dates.append(date_obj.strftime(\"%Y-%m-%d\"))\n",
    "\t\t#years.append(date_obj.year)\n",
    "\t\t#months.append(date_obj.month)\n",
    "\t\t#days.append(date_obj.day)\n",
    "\t\t#day_indexes.append((date_obj.date() - date(2000, 1, 1)).days)\n",
    "\t\tdays_since_first_mon = (date_obj.date() - date(2000, 1, 3)).days % 7\n",
    "\t\t#match days_since_first_mon:\n",
    "\t\t#\tcase 0:\n",
    "\t\t#\t\tday_of_week = 'Monday'\n",
    "\t\t#\tcase 1:\n",
    "\t\t#\t\tday_of_week = 'Tuesday'\n",
    "\t\t#\tcase 2:\n",
    "\t\t#\t\tday_of_week = 'Wednesday'\n",
    "\t\t#\tcase 3:\n",
    "\t\t#\t\tday_of_week = 'Thursday'\n",
    "\t\t#\tcase 4:\n",
    "\t\t#\t\tday_of_week = 'Friday'\n",
    "\t\t#\tcase 5:\n",
    "\t\t#\t\tday_of_week = 'Saturday'\n",
    "\t\t#\tcase 6:\n",
    "\t\t#\t\tday_of_week = 'Sunday'\n",
    "\t\t#\tcase _:\n",
    "\t\t#\t\tday_of_week = None\n",
    "\t\tdays_of_week.append(days_since_first_mon)\n",
    "\n",
    "\t#return dates, years, months, days, day_indexes, days_of_week\n",
    "\treturn days_of_week\n",
    "\n",
    "# The only one of value might be day of week, but as an int\n",
    "#dates, years, months, days, date_indexes, days_of_week = process_date(extracted['Date'])\n",
    "days_of_week = process_date(extracted['Date'])\n",
    "#extracted['Date'] = dates\n",
    "extracted.insert(8,'Day_of_week', days_of_week)\n",
    "#extracted.insert(8, 'DayIndex', date_indexes)\n",
    "#extracted.insert(8,'Day', days)\n",
    "#extracted.insert(8,'Month', months)\n",
    "#extracted.insert(8,'Year', years)\n",
    "\n",
    "# Remove the location and date columns since they're no longer needed\n",
    "extracted.drop(columns=['Location', 'Date'], inplace=True)\n",
    "extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconfigure(_df: pd.DataFrame):\n",
    "\t# Create sequential IDs within each group\n",
    "\t_df_with_ids = _df.copy()\n",
    "\t_df_with_ids['ID'] = _df_with_ids.groupby(['SCATS', 'Direction', 'Day_of_week']).cumcount()\n",
    "\n",
    "\t# Create the MultiIndex\n",
    "\t_df_with_ids = _df_with_ids.set_index(['SCATS', 'Direction', 'Day_of_week', 'ID'])\n",
    "\n",
    "\treturn _df_with_ids\n",
    "\n",
    "reconfigured = reconfigure(extracted)\n",
    "reconfigured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to csv\n",
    "reconfigured.to_csv('./processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(_df: pd.DataFrame):\n",
    "\t'''Take the information from a dataframe and create a graph from it.'''\n",
    "\n",
    "\tlocations: dict[int, tuple[float, float]] = {}\n",
    "\tstreet_to_nodes: dict[str, list[int]] = {}\n",
    "\n",
    "\tfor _, row in _df.iterrows():\n",
    "\t\tscats_num: int = row['SCATS']\n",
    "\t\tlatitude: float = row['Latitude']\n",
    "\t\tlongitude: float = row['Longitude']\n",
    "\t\tloc_desc: str = row['Intersection']\n",
    "\n",
    "\t\t# Locations is easy to set up\n",
    "\t\tlocations[scats_num] = (latitude, longitude)\n",
    "\n",
    "\t\t# Split the location description by '/' to get individual streets\n",
    "\t\t# Clean and process each street name\n",
    "\t\tstreets = [street.strip() for street in loc_desc.split('/')]\n",
    "\n",
    "\t\t# Associate each street with the SCATS number\n",
    "\t\tfor street in streets:\n",
    "\t\t\tif street:\n",
    "\t\t\t\tif street not in street_to_nodes:\n",
    "\t\t\t\t\tstreet_to_nodes[street] = []\n",
    "\t\t\t\tstreet_to_nodes[street].append(scats_num)\n",
    "\n",
    "\tedge_dict = defaultdict(lambda: defaultdict(int))  # Nested defaultdict for {node: {connected_node: cost}}\n",
    "\n",
    "\t# Connect a node to all other nodes with the same street\n",
    "\tfor _, nodes in street_to_nodes.items():\n",
    "\t\tfor node in nodes:\n",
    "\t\t\t# Add all other nodes from this street as edges with default cost 1\n",
    "\t\t\tfor connected_node in nodes:\n",
    "\t\t\t\tif connected_node != node:\n",
    "\t\t\t\t\tedge_dict[node][connected_node] = 1\n",
    "\n",
    "\t# Convert to a regular dictionary\n",
    "\tedges: dict[int, dict[int, int]] = {node: dict(connected_nodes) for node, connected_nodes in edge_dict.items()}\n",
    "\n",
    "\treturn locations, edges\n",
    "\n",
    "locations, edges = create_graph(extracted)\n",
    "print(locations)\n",
    "print(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print basic graph info\n",
    "print(f'Number of nodes (intersections): {len(locations)}')\n",
    "print(f'Number of edges (street connections): {len(edges)}')\n",
    "\n",
    "# List all nodes and their attributes\n",
    "for node, (latitude, longitude) in locations.items():\n",
    "\tprint(f'{node:4}: ({latitude:.6f}, {longitude:.6f})')\n",
    "\n",
    "# List all edges and their cost\n",
    "for node, others in edges.items():\n",
    "\tfor other, cost in others.items():\n",
    "\t\tprint(f'{node:4} -- {other:4}: Cost = {cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import search\n",
    "\n",
    "method = search.select_method('DFS')\n",
    "\n",
    "if method is None:\n",
    "\tprint(\"Incorrect method type, valid methods:\\nDFS, BFS, GBFS, AS, CUS1, CUS2, IDS, BS\")\n",
    "\tquit()\n",
    "\n",
    "graph = search.Graph(edges)\n",
    "graph.locations = locations\n",
    "\n",
    "origin = 4030\n",
    "goals = [4051]\n",
    "\n",
    "problem = search.GraphProblem(origin, goals, graph)\n",
    "\n",
    "result, count = method(problem, True)\n",
    "\n",
    "print('method=AS')\n",
    "# \\n\n",
    "# Ouput goal node\n",
    "print('goal=', goals, sep='', end=' | ')\n",
    "\n",
    "# Output number (length of path)\n",
    "print('number of nodes=', count, sep='')\n",
    "# \\n\n",
    "if (result is not None):\n",
    "\t# Output path: list of nodes\n",
    "\tprint('path=', result.solution(), sep='')\n",
    "else:\n",
    "\tprint('No path found!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
